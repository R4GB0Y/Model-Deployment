# Model Deployment Testing Laboratory

Welcome to the Model Deployment Testing Laboratory. Here, we explore different methods of deploying machine learning models, evaluating their performance, and ensuring scalability. Our key focus areas include:

## 1. FastAPI Deployment
Experience the efficiency of deploying Natural Language Processing (NLP) models with FastAPI. This section includes:
   - **NLP Model Deployment:** Steps to deploy a transformer model using FastAPI.
   - **API Testing Screenshots:** Visual evidence of API functionality, featuring FastAPI and Postman interfaces.
     - ![FastAPI Interface](https://github.com/R4GB0Y/Model-Deployment/blob/main/fastAPI1.PNG?raw=true)

     - ![Postman Test](https://github.com/R4GB0Y/Model-Deployment/assets/76519142/4dbf6aee-1aac-4802-829f-32f8adbdbb46)

## 2. API Containerization with Docker
Streamline your deployment process with Docker. This section demonstrates:
   - **Docker Container Setup:** Detailed instructions for encapsulating the API in a Docker container.
   - **Deployment Screenshots:** Visual guides to assist in Docker containerization.
     - ![Docker Setup](https://github.com/R4GB0Y/Model-Deployment/assets/76519142/2d217a68-ab58-4d0b-8a94-ef82911b7465)

## 3. TensorFlow Extended (TFX) for Model Serving
Leverage TensorFlow Extended (TFX) for deploying transformer models. Highlights include:
   - **TFX Model Serving:** Guide to serve models efficiently using TensorFlow Extended.
   - **Deployment Screenshot:** Visual proof of TFX in action.
     - ![TFX Model Serving](https://github.com/R4GB0Y/Model-Deployment/assets/76519142/91abfd16-4424-4511-ac56-3127d06a80c1)

## 4. Load Testing with Locust
Assess the robustness of your deployments under varying loads using Locust. This includes:
   - **Performance Testing Guide:** Detailed instructions for conducting load tests.
   - **Locust Testing Screenshot:** Evidence of load testing in practice.
     - ![Locust Load Test]([https://github.com/R4GB0Y/Model-Deployment/assets/76519142/57675693-de26-41af-aac5-45706db5e5f0](https://github.com/R4GB0Y/Model-Deployment/blob/main/result.PNG))

## Getting Started
To begin, navigate to the respective directories for detailed instructions on each deployment method:
- [FastAPI Deployment](1. fastAPI_Transformer_model_serving)
- [Docker Containerization](2. Dockerizing_API)
- [TensorFlow Extended (TFX) Deployment](3. Faster_Transformer_model_serving_using_Tensorflow_Extended)
- [Load Testing with Locust](4. Load_testing_using_Locust)
